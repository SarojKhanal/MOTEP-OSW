{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1bfe4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest site_id for ATLSHR (latitude 39.189972 and longitude -74.2) is: 62537\n",
      "Closest site_id for OCN1 (latitude 39.1 and longitude -74.299972) is: 61111\n",
      "Closest site_id for OCN2 (latitude 39.071 and longitude -74.424) is: 60466\n",
      "Closest site_id for SKPJK1 (latitude 38.649972 and longitude -74.7) is: 55106\n",
      "Closest site_id for SKPJK2 (latitude 38.67 and longitude -74.7) is: 55106\n",
      "Closest site_id for MRWN (latitude 38.252 and longitude -74.778) is: 50971\n",
      "Closest site_id for MMTM (latitude 38.34 and longitude -74.76) is: 51892\n",
      "Closest site_id for CVOW (latitude 36.947 and longitude -75.217) is: 43111\n",
      "[('ATLSHR', '62537'), ('OCN1', '61111'), ('OCN2', '60466'), ('SKPJK1', '55106'), ('SKPJK2', '55106'), ('MRWN', '50971'), ('MMTM', '51892'), ('CVOW', '43111')]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "def read_sites_from_file(filename):\n",
    "    sites = []\n",
    "    with open(filename, 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            sites.append({\n",
    "                'site_id': row['site_id'],\n",
    "                'latitude': float(row['latitude']),\n",
    "                'longitude': float(row['longitude'])\n",
    "            })\n",
    "    return sites\n",
    "\n",
    "def find_closest_site_id(sites, lat, lon):\n",
    "    min_distance = float('inf')\n",
    "    closest_site_id = None\n",
    "\n",
    "    for site in sites:\n",
    "        distance = math.sqrt((lat - site['latitude'])**2 + (lon - site['longitude'])**2)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_site_id = site['site_id']\n",
    "\n",
    "    return closest_site_id\n",
    "\n",
    "def main():\n",
    "    sites = read_sites_from_file('wtk_site_metadata.csv')\n",
    "\n",
    "    nodes = {\n",
    "    \"ATLSHR\" : (39.189972, -74.200000),\n",
    "    \"OCN1\" : (39.100000, -74.299972),\n",
    "    \"OCN2\" : (39.071, -74.424),\n",
    "    \"SKPJK1\" : (38.649972, -74.700000),\n",
    "    \"SKPJK2\" : (38.670000, -74.700000),\n",
    "    \"MRWN\" : (38.252, -74.778),\n",
    "    \"MMTM\" : (38.340000, -74.760000),\n",
    "    \"CVOW\" : (36.947, -75.217),\n",
    "    }\n",
    "\n",
    "    matched_sites = []\n",
    "    for location, (lat, lon) in nodes.items():\n",
    "        site_id = find_closest_site_id(sites, lat, lon)\n",
    "        print(f\"Closest site_id for {location} (latitude {lat} and longitude {lon}) is: {site_id}\")\n",
    "        matched_sites.append((location, site_id))\n",
    "        \n",
    "    print(matched_sites)\n",
    "        \n",
    "  \n",
    "        # Writing matched sites to a new CSV file\n",
    "    with open('wtk_site_metadata.csv', 'r') as input_csv, open('wtk_site_metadata_matched.csv', 'w', newline='') as output_csv:\n",
    "        reader = csv.DictReader(input_csv)\n",
    "        writer = csv.DictWriter(output_csv, fieldnames=reader.fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for row in reader:\n",
    "            for site in [int(site_id) for _, site_id in matched_sites]:\n",
    "                if int(row['site_id']) == site:\n",
    "                    writer.writerow(row)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6493c191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.9.0\n",
      "  latest version: 23.10.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c anaconda conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=23.10.0\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/skhanal/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - netcdf4\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    certifi-2023.11.17         |  py311hca03da5_0         161 KB  anaconda\n",
      "    openssl-3.0.12             |       h1a28f6b_0         4.5 MB  anaconda\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         4.7 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  certifi                         2023.7.22-py311hca03da5_0 --> 2023.11.17-py311hca03da5_0 \n",
      "  openssl                                 3.0.11-h1a28f6b_2 --> 3.0.12-h1a28f6b_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "certifi-2023.11.17   | 161 KB    |                                       |   0% \n",
      "certifi-2023.11.17   | 161 KB    | ###6                                  |  10% \u001b[A\n",
      "certifi-2023.11.17   | 161 KB    | ##################################### | 100% \u001b[A\n",
      "openssl-3.0.12       | 4.5 MB    | #9                                    |   5% \u001b[A\n",
      "openssl-3.0.12       | 4.5 MB    | ########6                             |  23% \u001b[A\n",
      "openssl-3.0.12       | 4.5 MB    | ###########8                          |  32% \u001b[A\n",
      "openssl-3.0.12       | 4.5 MB    | #####################                 |  57% \u001b[A\n",
      "openssl-3.0.12       | 4.5 MB    | ###########################6          |  75% \u001b[A\n",
      "openssl-3.0.12       | 4.5 MB    | ##################################### | 100% \u001b[A\n",
      "                                                                                \u001b[A\n",
      "                                                                                \u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c anaconda netcdf4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acebab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "def read_nc_file(file_path):\n",
    "    \"\"\"Read the netCDF file and return its data.\"\"\"\n",
    "    with Dataset(file_path, 'r') as nc_file:\n",
    "        # Here we are assuming all variables in the netCDF file should be read.\n",
    "        # If you only want specific variables, you can modify this section.\n",
    "        return {var: nc_file.variables[var][:].tolist() for var in nc_file.variables}\n",
    "\n",
    "def main():\n",
    "    # List of your netCDF files\n",
    "    nc_files = [\"43111.nc\", \"50971.nc\", \"51892.nc\", \"55106.nc\", \"55106.nc\", \"60466.nc\", \"61111.nc\", \"62537.nc\"]\n",
    "\n",
    "    data_dicts = [read_nc_file(file) for file in nc_files]\n",
    "    headers = [os.path.splitext(file)[0] for file in nc_files]\n",
    "\n",
    "    # Assume all netCDF files have the same variables and length\n",
    "    variable_names = list(data_dicts[0].keys())\n",
    "    data_length = len(data_dicts[0][variable_names[0]])\n",
    "\n",
    "    with open('wind_out.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        \n",
    "        # Write headers\n",
    "        writer.writerow(['Variable'] + headers)\n",
    "\n",
    "        for var in variable_names:\n",
    "            for i in range(data_length):\n",
    "                writer.writerow([var] + [data_dict[var][i] for data_dict in data_dicts])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed24365",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
